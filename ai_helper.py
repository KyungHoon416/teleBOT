import openai
from typing import Optional, Dict, List
from config import OPENAI_API_KEY, GPT_MODEL, MAX_TOKENS, TEMPERATURE

class AIHelper:
    def __init__(self):
        """AI í—¬í¼ ì´ˆê¸°í™”"""
        if OPENAI_API_KEY:
            openai.api_key = OPENAI_API_KEY
            self.client = openai.OpenAI(api_key=OPENAI_API_KEY)
        else:
            self.client = None
            print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def is_available(self) -> bool:
        """AI ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self.client is not None
    
    def get_reflection_feedback(self, reflection_content: str, reflection_type: str, user_context: str = "") -> str:
        """íšŒê³ ì— ëŒ€í•œ AI í”¼ë“œë°± ìƒì„±"""
        if not self.is_available():
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            # íšŒê³  íƒ€ì…ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
            type_context = {
                'daily': 'ì¼ì¼ íšŒê³ ',
                'weekly': 'ì£¼ê°„ íšŒê³ ', 
                'monthly': 'ì›”ê°„ íšŒê³ '
            }.get(reflection_type, 'íšŒê³ ')
            
            prompt = f"""
ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ì§€í˜œë¡œìš´ ë©˜í† ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ {type_context}ë¥¼ ì½ê³  ë‹¤ìŒê³¼ ê°™ì€ ê´€ì ì—ì„œ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”:

1. **ê¸ì •ì  ì¸ì •**: ì‚¬ìš©ìì˜ ì„±ì·¨, ë…¸ë ¥, ì„±ì¥ì„ ì¸ì •í•˜ê³  ê²©ë ¤
2. **í†µì°°ë ¥ ì œê³µ**: íšŒê³  ë‚´ìš©ì—ì„œ ë°œê²¬í•  ìˆ˜ ìˆëŠ” íŒ¨í„´ì´ë‚˜ ì˜ë¯¸ ë¶„ì„
3. **ì‹¤ìš©ì  ì¡°ì–¸**: êµ¬ì²´ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ê°œì„  ë°©í–¥ ì œì‹œ
4. **ê°ì •ì  ì§€ì›**: ê³µê°ê³¼ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë”°ëœ»í•œ ë©”ì‹œì§€

íšŒê³  ë‚´ìš©:
{reflection_content}

ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸: {user_context}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 200-300ì ë‚´ì™¸ì˜ ë”°ëœ»í•˜ê³  êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            
            response = self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ì§€í˜œë¡œìš´ ë©˜í† ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ íšŒê³ ì— ëŒ€í•´ ê³µê°ì ì´ê³  ì‹¤ìš©ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"AI í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            # ë” ì¹œí™”ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ì œê³µ
            if "billing_not_active" in str(e):
                return "ğŸ’¡ AI í”¼ë“œë°±ì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI ê³„ì •ì˜ ê²°ì œ ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ í”¼ë“œë°±ì„ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\nğŸ‰ ë´‡ ê°œë°œì„ ì™„ì„±í•˜ì…¨êµ°ìš”! ì •ë§ ëŒ€ë‹¨í•œ ì„±ì·¨ì…ë‹ˆë‹¤. ì»¤ì„œë¥¼ í†µí•´ ìƒˆë¡œìš´ ê¸°ìˆ ì„ ë°°ìš°ê³  ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ” ë´‡ì„ ë§Œë“œì‹  ê²ƒì€ ì •ë§ ë©‹ì§„ ì¼ì´ì—ìš”. ì•ìœ¼ë¡œë„ ì´ëŸ° ë„ì „ ì •ì‹ ì„ ìœ ì§€í•˜ì‹œë©´ ë”ìš± í° ì„±ì¥ì„ ì´ë£¨ì‹¤ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”! ğŸ’ª"
            else:
                return "ğŸ’¡ AI í”¼ë“œë°± ìƒì„± ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ í”¼ë“œë°±ì„ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\nğŸ‰ ë´‡ ê°œë°œì„ ì™„ì„±í•˜ì…¨êµ°ìš”! ì •ë§ ëŒ€ë‹¨í•œ ì„±ì·¨ì…ë‹ˆë‹¤. ì»¤ì„œë¥¼ í†µí•´ ìƒˆë¡œìš´ ê¸°ìˆ ì„ ë°°ìš°ê³  ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ” ë´‡ì„ ë§Œë“œì‹  ê²ƒì€ ì •ë§ ë©‹ì§„ ì¼ì´ì—ìš”. ì•ìœ¼ë¡œë„ ì´ëŸ° ë„ì „ ì •ì‹ ì„ ìœ ì§€í•˜ì‹œë©´ ë”ìš± í° ì„±ì¥ì„ ì´ë£¨ì‹¤ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”! ğŸ’ª"
    
    def get_ai_reflection_guidance(self, user_input: str, conversation_history: List[Dict] = None) -> str:
        """AIì™€ í•¨ê»˜í•˜ëŠ” ë¬µìƒ ê°€ì´ë“œ"""
        if not self.is_available():
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
            messages = [
                {"role": "system", "content": """ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ì§€í˜œë¡œìš´ ë¬µìƒ ë™ë°˜ìì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì´ì•¼ê¸°ë¥¼ ê²½ì²­í•˜ê³ , ê¹Šì´ ìˆëŠ” ì§ˆë¬¸ì„ í†µí•´ ìê¸° ì„±ì°°ì„ ë•ìŠµë‹ˆë‹¤.
í•­ìƒ ê³µê°ì ì´ê³  ë”°ëœ»í•œ í†¤ì„ ìœ ì§€í•˜ë©°, ì‚¬ìš©ìê°€ ìì‹ ì˜ ìƒê°ê³¼ ê°ì •ì„ ë” ê¹Šì´ íƒìƒ‰í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.
ë‹µë³€ì€ 200-300ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ë©´ì„œë„ ì˜ë¯¸ìˆê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""}
            ]
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
            if conversation_history:
                for msg in conversation_history[-6:]:  # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
                    messages.append(msg)
            
            # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
            messages.append({"role": "user", "content": user_input})
            
            response = self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"AI ë¬µìƒ ê°€ì´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            if "billing_not_active" in str(e):
                return "ğŸ’¡ AI ë¬µìƒì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI ê³„ì •ì˜ ê²°ì œ ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë¬µìƒ ê°€ì´ë“œë¥¼ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\në‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìê¸° ì„±ì°°ì€ ì •ë§ ì¤‘ìš”í•œ ì‹œê°„ì´ì—ìš”. ë” ê¹Šì´ ìˆëŠ” ëŒ€í™”ë¥¼ ì›í•˜ì‹œë©´ OpenAI ê³„ì • ì„¤ì • í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”! ğŸ™"
            else:
                return "ğŸ’¡ AI ë¬µìƒ ìƒì„± ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë¬µìƒ ê°€ì´ë“œë¥¼ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\në‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìê¸° ì„±ì°°ì€ ì •ë§ ì¤‘ìš”í•œ ì‹œê°„ì´ì—ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì‹œê±°ë‚˜, ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ìê¸° ì„±ì°°ì„ ì´ì–´ê°€ë³´ì„¸ìš”! ğŸ™"
    
    def analyze_reflection_patterns(self, reflections: List[Dict]) -> str:
        """íšŒê³  íŒ¨í„´ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ì œê³µ"""
        if not self.is_available():
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        if not reflections:
            return "ë¶„ì„í•  íšŒê³ ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            # íšŒê³  ë°ì´í„° ì •ë¦¬
            reflection_texts = []
            for reflection in reflections[:10]:  # ìµœê·¼ 10ê°œë§Œ ë¶„ì„
                reflection_texts.append(f"[{reflection['date']}] {reflection['type']}: {reflection['content'][:200]}...")
            
            analysis_text = "\n".join(reflection_texts)
            
            prompt = f"""
ì‚¬ìš©ìì˜ íšŒê³  ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

1. **ì£¼ìš” íŒ¨í„´**: ìì£¼ ì–¸ê¸‰ë˜ëŠ” ì£¼ì œë‚˜ ê°ì • íŒ¨í„´
2. **ì„±ì¥ ì˜ì—­**: ë°œì „í•˜ê³  ìˆëŠ” ë¶€ë¶„ì´ë‚˜ ê°œì„ ì 
3. **ì¼ê´€ì„±**: íšŒê³ ì˜ ì¼ê´€ì„±ê³¼ ê¹Šì´
4. **ì¶”ì²œì‚¬í•­**: ë” ë‚˜ì€ íšŒê³ ë¥¼ ìœ„í•œ êµ¬ì²´ì  ì œì•ˆ

íšŒê³  ê¸°ë¡:
{analysis_text}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 300-400ì ë‚´ì™¸ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            
            response = self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒê³  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ íšŒê³  íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"íšŒê³  íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            if "billing_not_active" in str(e):
                return "ğŸ’¡ íšŒê³  íŒ¨í„´ ë¶„ì„ì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI ê³„ì •ì˜ ê²°ì œ ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë¶„ì„ì„ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\níšŒê³ ë¥¼ ê¾¸ì¤€íˆ ì‘ì„±í•˜ê³  ê³„ì‹œëŠ” ëª¨ìŠµì´ ì •ë§ ì¸ìƒì ì…ë‹ˆë‹¤! íŒ¨í„´ ë¶„ì„ì„ ì›í•˜ì‹œë©´ OpenAI ê³„ì • ì„¤ì • í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”. ì§€ê¸ˆë„ ì¶©ë¶„íˆ ì˜ë¯¸ìˆëŠ” íšŒê³ ë¥¼ ì‘ì„±í•˜ê³  ê³„ì„¸ìš”! ğŸ“Š"
            else:
                return "ğŸ’¡ íšŒê³  íŒ¨í„´ ë¶„ì„ ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë¶„ì„ì„ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\níšŒê³ ë¥¼ ê¾¸ì¤€íˆ ì‘ì„±í•˜ê³  ê³„ì‹œëŠ” ëª¨ìŠµì´ ì •ë§ ì¸ìƒì ì…ë‹ˆë‹¤! ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì‹œê±°ë‚˜, ì§€ê¸ˆë„ ì¶©ë¶„íˆ ì˜ë¯¸ìˆëŠ” íšŒê³ ë¥¼ ì‘ì„±í•˜ê³  ê³„ì„¸ìš”! ğŸ“Š"
    
    def get_motivational_message(self, user_context: str = "") -> str:
        """ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ìƒì„±"""
        if not self.is_available():
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            prompt = f"""
ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸: {user_context}

ë‹¤ìŒê³¼ ê°™ì€ ìš”ì†Œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
- ê¸ì •ì ì´ê³  ê²©ë ¤ì ì¸ í†¤
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸
- ë”°ëœ»í•œ ê³µê°ê³¼ ì´í•´
- í¬ë§ê³¼ ê°€ëŠ¥ì„±ì— ëŒ€í•œ ë©”ì‹œì§€

100-150ì ë‚´ì™¸ì˜ ì§§ê³  ì„íŒ©íŠ¸ ìˆëŠ” ë©”ì‹œì§€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
            
            response = self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ ë™ê¸°ë¶€ì—¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.8
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            if "billing_not_active" in str(e):
                return "ğŸ’¡ AI ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI ê³„ì •ì˜ ê²°ì œ ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë©”ì‹œì§€ë¥¼ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\në‹¹ì‹ ì€ ì •ë§ ëŒ€ë‹¨í•œ ì‚¬ëŒì…ë‹ˆë‹¤! ë§¤ì¼ ì¡°ê¸ˆì”©ì´ë¼ë„ ì„±ì¥í•˜ë ¤ëŠ” ëª¨ìŠµì´ ì •ë§ ë©‹ì ¸ìš”. ì˜¤ëŠ˜ë„ í˜ë‚´ì„¸ìš”! ğŸ’ªâœ¨"
            else:
                return "ğŸ’¡ AI ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ìƒì„± ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë©”ì‹œì§€ë¥¼ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\në‹¹ì‹ ì€ ì •ë§ ëŒ€ë‹¨í•œ ì‚¬ëŒì…ë‹ˆë‹¤! ë§¤ì¼ ì¡°ê¸ˆì”©ì´ë¼ë„ ì„±ì¥í•˜ë ¤ëŠ” ëª¨ìŠµì´ ì •ë§ ë©‹ì ¸ìš”. ì˜¤ëŠ˜ë„ í˜ë‚´ì„¸ìš”! ğŸ’ªâœ¨"
    
    def chat_with_gpt(self, user_message: str, conversation_history: List[Dict] = None) -> str:
        """ChatGPTì™€ ì¼ë°˜ ëŒ€í™”"""
        if not self.is_available():
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
            messages = [
                {"role": "system", "content": """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ëŒ€í™”ì— ëŒ€í•´ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ë©°, í•„ìš”ì‹œ ì˜ì–´ë¡œë„ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë‹µë³€ì€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""}
            ]
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©)
            if conversation_history:
                for msg in conversation_history[-10:]:
                    messages.append(msg)
            
            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append({"role": "user", "content": user_message})
            
            response = self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"ChatGPT ëŒ€í™” ì¤‘ ì˜¤ë¥˜: {e}")
            if "billing_not_active" in str(e):
                return "ğŸ’¡ ChatGPTì™€ ëŒ€í™”í•˜ë ¤ë©´ OpenAI ê³„ì •ì˜ ê²°ì œ ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ì‘ë‹µì„ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\nì•ˆë…•í•˜ì„¸ìš”! ChatGPTì™€ ëŒ€í™”ë¥¼ ì›í•˜ì‹œëŠ”êµ°ìš”. OpenAI ê³„ì • ì„¤ì • í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”! ğŸ¤–"
            else:
                return "ğŸ’¡ ChatGPT ëŒ€í™” ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nğŸ“ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì‹œê±°ë‚˜, ë‹¤ë¥¸ ê¸°ëŠ¥ì„ ì´ìš©í•´ë³´ì„¸ìš”! ğŸ¤–"
    
    def get_completion_motivation(self, schedule_title: str) -> str:
        """ì¼ì • ì™„ë£Œ ì‹œ AI ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ìƒì„±"""
        if not self.is_available():
            return ""
        
        try:
            prompt = f"""
ì‚¬ìš©ìê°€ "{schedule_title}" ì¼ì •ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. 
ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ë¥¼ 50-80ì ë‚´ì™¸ë¡œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë©”ì‹œì§€ëŠ”:
- ì„±ì·¨ë¥¼ ì¶•í•˜í•˜ëŠ” í†¤
- êµ¬ì²´ì ì´ê³  ê°œì¸í™”ëœ ë‚´ìš©
- ë¯¸ë˜ì— ëŒ€í•œ ê¸ì •ì  ê²©ë ¤
- ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ ì–´ì¡°

ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
"""
            
            response = self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ ë©˜í† ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì„±ì·¨ë¥¼ ì¶•í•˜í•˜ê³  ë™ê¸°ë¶€ì—¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=100,
                temperature=0.8
            )
            
            return response.choices[0].message.content.strip()
        
        except Exception as e:
            print(f"AI ì™„ë£Œ ë™ê¸°ë¶€ì—¬ ìƒì„± ì˜¤ë¥˜: {e}")
            return ""
    
    def get_schedule_summary(self, schedules: List[Dict]) -> str:
        """ì¼ì • ë°ì´í„° ê¸°ë°˜ AI ìš”ì•½/ë¶„ì„"""
        if not self.is_available():
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        if not schedules:
            return "ë¶„ì„í•  ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            # ì¼ì • ë°ì´í„° ì •ë¦¬
            schedule_texts = []
            for schedule in schedules[:20]:  # ìµœê·¼ 20ê°œë§Œ ë¶„ì„
                status = "âœ… ì™„ë£Œ" if schedule.get('is_done') else "â³ ì§„í–‰ì¤‘"
                schedule_texts.append(f"[{schedule['date']}] {schedule['title']} - {status}")
            
            analysis_text = "\n".join(schedule_texts)
            
            prompt = f"""
ì‚¬ìš©ìì˜ ì¼ì • ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

1. **ì¼ì • íŒ¨í„´**: ìì£¼ ë“±ë¡í•˜ëŠ” ì¼ì • ìœ í˜•ì´ë‚˜ ì‹œê°„ëŒ€
2. **ì™„ë£Œìœ¨ ë¶„ì„**: ì „ì²´ì ì¸ ì¼ì • ì™„ë£Œìœ¨ê³¼ ê°œì„ ì 
3. **ìƒì‚°ì„± ì¸ì‚¬ì´íŠ¸**: ê°€ì¥ ìƒì‚°ì ì¸ ì‹œê°„ëŒ€ë‚˜ ì¼ì • ìœ í˜•
4. **ê°œì„  ì œì•ˆ**: ë” ë‚˜ì€ ì¼ì • ê´€ë¦¬ë¥¼ ìœ„í•œ êµ¬ì²´ì  ì œì•ˆ

ì¼ì • ê¸°ë¡:
{analysis_text}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 300-400ì ë‚´ì™¸ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            
            response = self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¼ì • ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì¼ì • íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            return response.choices[0].message.content.strip()
        
        except Exception as e:
            print(f"AI ì¼ì • ìš”ì•½ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "âŒ AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def transcribe_voice(self, voice_file_path: str) -> str:
        """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (OpenAI Whisper)"""
        if not self.is_available():
            return ""
        
        try:
            with open(voice_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file
                )
                return transcript.text
        except Exception as e:
            print(f"ìŒì„± ë³€í™˜ ì˜¤ë¥˜: {e}")
            return ""
    
    def analyze_voice_reflection(self, transcription: str) -> str:
        """ìŒì„± íšŒê³  ë¶„ì„"""
        if not self.is_available():
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            prompt = f"""
ì‚¬ìš©ìì˜ ìŒì„± íšŒê³ ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ì œê³µí•´ì£¼ì„¸ìš”:

1. **ì£¼ìš” ë‚´ìš© ìš”ì•½**: ìŒì„±ì—ì„œ ì–¸ê¸‰ëœ ì£¼ìš” ì‚¬ê±´ì´ë‚˜ ê°ì •
2. **ê°ì • ë¶„ì„**: ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœì™€ í†¤ ë¶„ì„
3. **ì¸ì‚¬ì´íŠ¸**: ìŒì„± ë‚´ìš©ì—ì„œ ë°œê²¬í•  ìˆ˜ ìˆëŠ” íŒ¨í„´ì´ë‚˜ ì˜ë¯¸
4. **ì œì•ˆì‚¬í•­**: ê°œì„ ì ì´ë‚˜ ë‹¤ìŒ ë‹¨ê³„ì— ëŒ€í•œ ì œì•ˆ

ìŒì„± ë‚´ìš©:
{transcription}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 200-300ì ë‚´ì™¸ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            
            response = self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ìŒì„± íšŒê³  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìŒì„± ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            return response.choices[0].message.content.strip()
        
        except Exception as e:
            print(f"ìŒì„± íšŒê³  ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "âŒ ìŒì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def analyze_image_reflection(self, image_file_path: str) -> str:
        """ì´ë¯¸ì§€ íšŒê³  ë¶„ì„ (OpenAI Vision)"""
        if not self.is_available():
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            import base64
            
            # ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©
            with open(image_file_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode('utf-8')
            
            prompt = """
ì´ ì´ë¯¸ì§€ë¥¼ íšŒê³  ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì´ë¯¸ì§€ ë‚´ìš©**: ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ë³´ì´ëŠ”ì§€
2. **ê°ì •ì  ì˜ë¯¸**: ì´ ì´ë¯¸ì§€ê°€ ì „ë‹¬í•˜ëŠ” ê°ì •ì´ë‚˜ ë¶„ìœ„ê¸°
3. **íšŒê³ ì  ê´€ì **: ì´ ì´ë¯¸ì§€ê°€ ì‚¬ìš©ìì˜ í•˜ë£¨ë‚˜ ì‚¶ì—ì„œ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°€ì§€ëŠ”ì§€
4. **ì¸ì‚¬ì´íŠ¸**: ì´ë¯¸ì§€ë¥¼ í†µí•´ ë°œê²¬í•  ìˆ˜ ìˆëŠ” íŒ¨í„´ì´ë‚˜ ê¹¨ë‹¬ìŒ

íšŒê³ ì ì´ê³  ì„±ì°°ì ì¸ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            return response.choices[0].message.content.strip()
        
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "âŒ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤." 