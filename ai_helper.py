import openai
import aiofiles
from typing import Optional, Dict, List, Any
from config import OPENAI_API_KEY, GPT_MODEL, MAX_TOKENS, TEMPERATURE
from openai.types.chat import ChatCompletionMessageParam
from telegram import Update
from telegram.ext import ContextTypes

class AIHelper:
    def __init__(self):
        """AI í—¬í¼ ì´ˆê¸°í™”"""
        if OPENAI_API_KEY:
            self.client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)
        else:
            self.client = None
            print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def is_available(self) -> bool:
        """AI ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self.client is not None
    
    async def get_reflection_feedback(self, content: str, reflection_type: str = "daily") -> str:
        """
        Tí˜• íšŒê³ ë¥¼ Fí˜•(Feeling/Feedback/Forward) íšŒê³ ë¡œ ë³€í™˜í•´ì£¼ëŠ” AI í”¼ë“œë°± ìƒì„±
        """
        if not self.is_available() or not self.client:
            return "âŒ AI í”¼ë“œë°± ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        try:
            prompt = f"""
ì•„ë˜ëŠ” ì‚¬ìš©ìê°€ ì‘ì„±í•œ Tí˜• íšŒê³ ì…ë‹ˆë‹¤.

{content}

ì´ íšŒê³ ë¥¼ ë°”íƒ•ìœ¼ë¡œ, Fí˜• íšŒê³ (Feeling/Feedback/Forward) êµ¬ì¡°ë¡œ ì•„ë˜ì™€ ê°™ì´ ì•ˆë‚´í•´ì¤˜.

1. [Feeling] ê·¸ ì¼ì— ëŒ€í•´ ëŠë‚€ ê°ì •/ë§ˆìŒ/ìƒê°ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.
2. [Feedback] ì˜¤ëŠ˜ì˜ íšŒê³ ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë‚˜ ë°°ìš¸ ì ì„ ì§§ê²Œ ì •ë¦¬í•´ì¤˜.
3. [Forward] ì‹¤í˜„ ê°€ëŠ¥í•œ êµ¬ì²´ì  ëª©í‘œ/ì‹¤ì²œ ë°©ì•ˆì„ 1~2ê°€ì§€ ì œì•ˆí•´ì¤˜.
4. ë§ˆì§€ë§‰ìœ¼ë¡œ, í˜„ì‹¤ì ìœ¼ë¡œ ì‹¤ì²œí•  ìˆ˜ ìˆë„ë¡ ë”°ëœ»í•œ ë™ê¸°ë¶€ì—¬ì™€ ì‹¤ì²œ íŒì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•´ì¤˜.

ì•„ë˜ ì˜ˆì‹œì²˜ëŸ¼ ë‹µë³€í•´ì¤˜:

[Feeling] ...
[Feedback] ...
[Forward] ...
[ë™ê¸°ë¶€ì—¬] ...
"""
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ì‹¤ìš©ì ì¸ ìê¸°ì„±ì°° ì½”ì¹˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ íšŒê³ ë¥¼ Fí˜• êµ¬ì¡°ë¡œ ì•ˆë‚´í•˜ê³ , ì‹¤í˜„ ê°€ëŠ¥í•œ ëª©í‘œì™€ ë™ê¸°ë¶€ì—¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            response = await self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=400,
                temperature=0.7
            )
            content = response.choices[0].message.content
            return content.strip() if content else ""
        except Exception as e:
            print(f"AI íšŒê³  í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {e}")
            return "AI íšŒê³  í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
    
    async def get_ai_reflection_guidance(self, user_input: str, conversation_history: Optional[List[Dict[str, Any]]] = None) -> str:
        """AIì™€ í•¨ê»˜í•˜ëŠ” ë¬µìƒ ê°€ì´ë“œ"""
        if not self.is_available() or not self.client:
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
            messages: List[ChatCompletionMessageParam] = [
                {"role": "system", "content": """ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ì§€í˜œë¡œìš´ ë¬µìƒ ë™ë°˜ìì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì´ì•¼ê¸°ë¥¼ ê²½ì²­í•˜ê³ , ê¹Šì´ ìˆëŠ” ì§ˆë¬¸ì„ í†µí•´ ìê¸° ì„±ì°°ì„ ë•ìŠµë‹ˆë‹¤.
í•­ìƒ ê³µê°ì ì´ê³  ë”°ëœ»í•œ í†¤ì„ ìœ ì§€í•˜ë©°, ì‚¬ìš©ìê°€ ìì‹ ì˜ ìƒê°ê³¼ ê°ì •ì„ ë” ê¹Šì´ íƒìƒ‰í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.
ë‹µë³€ì€ 200-300ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ë©´ì„œë„ ì˜ë¯¸ìˆê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""}
            ]
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
            if conversation_history:
                for msg in conversation_history[-6:]:  # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
                    if isinstance(msg, dict) and "role" in msg and "content" in msg:
                        messages.append({"role": msg["role"], "content": msg["content"]})
            
            # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
            messages.append({"role": "user", "content": user_input})
            
            response = await self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            content = response.choices[0].message.content
            return content.strip() if content else ""
            
        except Exception as e:
            print(f"AI ë¬µìƒ ê°€ì´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            if "billing_not_active" in str(e):
                return "ğŸ’¡ AI ë¬µìƒì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI ê³„ì •ì˜ ê²°ì œ ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë¬µìƒ ê°€ì´ë“œë¥¼ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\në‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìê¸° ì„±ì°°ì€ ì •ë§ ì¤‘ìš”í•œ ì‹œê°„ì´ì—ìš”. ë” ê¹Šì´ ìˆëŠ” ëŒ€í™”ë¥¼ ì›í•˜ì‹œë©´ OpenAI ê³„ì • ì„¤ì • í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”! ğŸ™"
            else:
                return "ğŸ’¡ AI ë¬µìƒ ìƒì„± ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë¬µìƒ ê°€ì´ë“œë¥¼ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\në‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìê¸° ì„±ì°°ì€ ì •ë§ ì¤‘ìš”í•œ ì‹œê°„ì´ì—ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì‹œê±°ë‚˜, ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ìê¸° ì„±ì°°ì„ ì´ì–´ê°€ë³´ì„¸ìš”! ğŸ™"
    
    async def analyze_reflection_patterns(self, reflections: List[Dict]) -> str:
        """íšŒê³  íŒ¨í„´ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ì œê³µ"""
        if not self.is_available() or not self.client:
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        if not reflections:
            return "ë¶„ì„í•  íšŒê³ ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            # íšŒê³  ë°ì´í„° ì •ë¦¬
            reflection_texts = []
            for reflection in reflections[:10]:  # ìµœê·¼ 10ê°œë§Œ ë¶„ì„
                reflection_texts.append(f"[{reflection['date']}] {reflection['type']}: {reflection['content'][:200]}...")
            
            analysis_text = "\n".join(reflection_texts)
            
            prompt = f"""
ì‚¬ìš©ìì˜ íšŒê³  ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

1. **ì£¼ìš” íŒ¨í„´**: ìì£¼ ì–¸ê¸‰ë˜ëŠ” ì£¼ì œë‚˜ ê°ì • íŒ¨í„´
2. **ì„±ì¥ ì˜ì—­**: ë°œì „í•˜ê³  ìˆëŠ” ë¶€ë¶„ì´ë‚˜ ê°œì„ ì 
3. **ì¼ê´€ì„±**: íšŒê³ ì˜ ì¼ê´€ì„±ê³¼ ê¹Šì´
4. **ì¶”ì²œì‚¬í•­**: ë” ë‚˜ì€ íšŒê³ ë¥¼ ìœ„í•œ êµ¬ì²´ì  ì œì•ˆ

íšŒê³  ê¸°ë¡:
{analysis_text}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 300-400ì ë‚´ì™¸ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            
            messages: List[ChatCompletionMessageParam] = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒê³  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ íšŒê³  íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            
            response = await self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            content = response.choices[0].message.content
            return content.strip() if content else ""
            
        except Exception as e:
            print(f"íšŒê³  íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            if "billing_not_active" in str(e):
                return "ğŸ’¡ íšŒê³  íŒ¨í„´ ë¶„ì„ì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI ê³„ì •ì˜ ê²°ì œ ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë¶„ì„ì„ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\níšŒê³ ë¥¼ ê¾¸ì¤€íˆ ì‘ì„±í•˜ê³  ê³„ì‹œëŠ” ëª¨ìŠµì´ ì •ë§ ì¸ìƒì ì…ë‹ˆë‹¤! íŒ¨í„´ ë¶„ì„ì„ ì›í•˜ì‹œë©´ OpenAI ê³„ì • ì„¤ì • í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”. ì§€ê¸ˆë„ ì¶©ë¶„íˆ ì˜ë¯¸ìˆëŠ” íšŒê³ ë¥¼ ì‘ì„±í•˜ê³  ê³„ì„¸ìš”! ğŸ“Š"
            else:
                return "ğŸ’¡ íšŒê³  íŒ¨í„´ ë¶„ì„ ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë¶„ì„ì„ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\níšŒê³ ë¥¼ ê¾¸ì¤€íˆ ì‘ì„±í•˜ê³  ê³„ì‹œëŠ” ëª¨ìŠµì´ ì •ë§ ì¸ìƒì ì…ë‹ˆë‹¤! ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì‹œê±°ë‚˜, ì§€ê¸ˆë„ ì¶©ë¶„íˆ ì˜ë¯¸ìˆëŠ” íšŒê³ ë¥¼ ì‘ì„±í•˜ê³  ê³„ì„¸ìš”! ğŸ“Š"
    
    async def get_motivational_message(self, user_context: str = "") -> str:
        """ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ìƒì„±"""
        if not self.is_available() or not self.client:
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            prompt = f"""
ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸: {user_context}

ë‹¤ìŒê³¼ ê°™ì€ ìš”ì†Œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
- ê¸ì •ì ì´ê³  ê²©ë ¤ì ì¸ í†¤
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸
- ë”°ëœ»í•œ ê³µê°ê³¼ ì´í•´
- í¬ë§ê³¼ ê°€ëŠ¥ì„±ì— ëŒ€í•œ ë©”ì‹œì§€

100-150ì ë‚´ì™¸ì˜ ì§§ê³  ì„íŒ©íŠ¸ ìˆëŠ” ë©”ì‹œì§€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
            
            messages: List[ChatCompletionMessageParam] = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ ë™ê¸°ë¶€ì—¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            
            response = await self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=300,
                temperature=0.8
            )
            
            content = response.choices[0].message.content
            return content.strip() if content else ""
            
        except Exception as e:
            print(f"ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            if "billing_not_active" in str(e):
                return "ğŸ’¡ AI ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI ê³„ì •ì˜ ê²°ì œ ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë©”ì‹œì§€ë¥¼ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\në‹¹ì‹ ì€ ì •ë§ ëŒ€ë‹¨í•œ ì‚¬ëŒì…ë‹ˆë‹¤! ë§¤ì¼ ì¡°ê¸ˆì”©ì´ë¼ë„ ì„±ì¥í•˜ë ¤ëŠ” ëª¨ìŠµì´ ì •ë§ ë©‹ì ¸ìš”. ì˜¤ëŠ˜ë„ í˜ë‚´ì„¸ìš”! ğŸ’ªâœ¨"
            else:
                return "ğŸ’¡ AI ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ìƒì„± ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ë©”ì‹œì§€ë¥¼ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\në‹¹ì‹ ì€ ì •ë§ ëŒ€ë‹¨í•œ ì‚¬ëŒì…ë‹ˆë‹¤! ë§¤ì¼ ì¡°ê¸ˆì”©ì´ë¼ë„ ì„±ì¥í•˜ë ¤ëŠ” ëª¨ìŠµì´ ì •ë§ ë©‹ì ¸ìš”. ì˜¤ëŠ˜ë„ í˜ë‚´ì„¸ìš”! ğŸ’ªâœ¨"
    
    async def chat_with_gpt(self, user_message: str, conversation_history: Optional[List[Dict[str, Any]]] = None) -> str:
        """ChatGPTì™€ ì¼ë°˜ ëŒ€í™”"""
        if not self.is_available() or not self.client:
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
            messages: List[ChatCompletionMessageParam] = [
                {"role": "system", "content": """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ëŒ€í™”ì— ëŒ€í•´ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ë©°, í•„ìš”ì‹œ ì˜ì–´ë¡œë„ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë‹µë³€ì€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""}
            ]
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©)
            if conversation_history:
                for msg in conversation_history[-10:]:
                    if isinstance(msg, dict) and "role" in msg and "content" in msg:
                        messages.append({"role": msg["role"], "content": msg["content"]})
            
            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append({"role": "user", "content": user_message})
            
            response = await self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            content = response.choices[0].message.content
            return content.strip() if content else ""
            
        except Exception as e:
            print(f"ChatGPT ëŒ€í™” ì¤‘ ì˜¤ë¥˜: {e}")
            if "billing_not_active" in str(e):
                return "ğŸ’¡ ChatGPTì™€ ëŒ€í™”í•˜ë ¤ë©´ OpenAI ê³„ì •ì˜ ê²°ì œ ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n\nğŸ“ ëŒ€ì‹  ê¸°ë³¸ ì‘ë‹µì„ ì œê³µí•´ë“œë¦´ê²Œìš”:\n\nì•ˆë…•í•˜ì„¸ìš”! ChatGPTì™€ ëŒ€í™”ë¥¼ ì›í•˜ì‹œëŠ”êµ°ìš”. OpenAI ê³„ì • ì„¤ì • í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”! ğŸ¤–"
            else:
                return "ğŸ’¡ ChatGPT ëŒ€í™” ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nğŸ“ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì‹œê±°ë‚˜, ë‹¤ë¥¸ ê¸°ëŠ¥ì„ ì´ìš©í•´ë³´ì„¸ìš”! ğŸ¤–"
    
    async def get_completion_motivation(self, schedule_title: str) -> str:
        """ì¼ì • ì™„ë£Œ ì‹œ AI ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ìƒì„±"""
        if not self.is_available() or not self.client:
            return ""
        
        try:
            prompt = f"""
ì‚¬ìš©ìê°€ "{schedule_title}" ì¼ì •ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. 
ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ë¥¼ 50-80ì ë‚´ì™¸ë¡œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë©”ì‹œì§€ëŠ”:
- ì„±ì·¨ë¥¼ ì¶•í•˜í•˜ëŠ” í†¤
- êµ¬ì²´ì ì´ê³  ê°œì¸í™”ëœ ë‚´ìš©
- ë¯¸ë˜ì— ëŒ€í•œ ê¸ì •ì  ê²©ë ¤
- ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ ì–´ì¡°

ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
"""
            
            messages: List[ChatCompletionMessageParam] = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ê²©ë ¤ì ì¸ ë©˜í† ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì„±ì·¨ë¥¼ ì¶•í•˜í•˜ê³  ë™ê¸°ë¶€ì—¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            
            response = await self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=100,
                temperature=0.8
            )
            
            content = response.choices[0].message.content
            return content.strip() if content else ""
        
        except Exception as e:
            print(f"AI ì™„ë£Œ ë™ê¸°ë¶€ì—¬ ìƒì„± ì˜¤ë¥˜: {e}")
            return ""
    
    async def get_schedule_summary(self, schedules: List[Dict]) -> str:
        """ì¼ì • ë°ì´í„° ê¸°ë°˜ AI ìš”ì•½/ë¶„ì„"""
        if not self.is_available() or not self.client:
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        if not schedules:
            return "ë¶„ì„í•  ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            # ì¼ì • ë°ì´í„° ì •ë¦¬
            schedule_texts = []
            for schedule in schedules[:20]:  # ìµœê·¼ 20ê°œë§Œ ë¶„ì„
                status = "âœ… ì™„ë£Œ" if schedule.get('is_done') else "â³ ì§„í–‰ì¤‘"
                schedule_texts.append(f"[{schedule['date']}] {schedule['title']} - {status}")
            
            analysis_text = "\n".join(schedule_texts)
            
            prompt = f"""
ì‚¬ìš©ìì˜ ì¼ì • ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

1. **ì¼ì • íŒ¨í„´**: ìì£¼ ë“±ë¡í•˜ëŠ” ì¼ì • ìœ í˜•ì´ë‚˜ ì‹œê°„ëŒ€
2. **ì™„ë£Œìœ¨ ë¶„ì„**: ì „ì²´ì ì¸ ì¼ì • ì™„ë£Œìœ¨ê³¼ ê°œì„ ì 
3. **ìƒì‚°ì„± ì¸ì‚¬ì´íŠ¸**: ê°€ì¥ ìƒì‚°ì ì¸ ì‹œê°„ëŒ€ë‚˜ ì¼ì • ìœ í˜•
4. **ê°œì„  ì œì•ˆ**: ë” ë‚˜ì€ ì¼ì • ê´€ë¦¬ë¥¼ ìœ„í•œ êµ¬ì²´ì  ì œì•ˆ

ì¼ì • ê¸°ë¡:
{analysis_text}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 300-400ì ë‚´ì™¸ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            
            messages: List[ChatCompletionMessageParam] = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¼ì • ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì¼ì • íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            
            response = await self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            content = response.choices[0].message.content
            return content.strip() if content else ""
        
        except Exception as e:
            print(f"AI ì¼ì • ìš”ì•½ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "âŒ AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def transcribe_voice(self, voice_file_path: str) -> str:
        """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (OpenAI Whisper)"""
        if not self.is_available() or not self.client:
            return ""
        
        try:
            async with aiofiles.open(voice_file_path, "rb") as audio_file:
                audio_bytes = await audio_file.read()
            import io
            audio_stream = io.BytesIO(audio_bytes)
            if hasattr(self.client, "audio") and hasattr(self.client.audio, "transcriptions"):
                transcript = await self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_stream
                )
                return transcript.text if transcript and hasattr(transcript, 'text') else ""
            else:
                return ""
        except Exception as e:
            print(f"ìŒì„± ë³€í™˜ ì˜¤ë¥˜: {e}")
            return ""
    
    async def analyze_voice_reflection(self, transcription: str) -> str:
        """ìŒì„± íšŒê³  ë¶„ì„"""
        if not self.is_available() or not self.client:
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            prompt = f"""
ì‚¬ìš©ìì˜ ìŒì„± íšŒê³ ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ì œê³µí•´ì£¼ì„¸ìš”:

1. **ì£¼ìš” ë‚´ìš© ìš”ì•½**: ìŒì„±ì—ì„œ ì–¸ê¸‰ëœ ì£¼ìš” ì‚¬ê±´ì´ë‚˜ ê°ì •
2. **ê°ì • ë¶„ì„**: ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœì™€ í†¤ ë¶„ì„
3. **ì¸ì‚¬ì´íŠ¸**: ìŒì„± ë‚´ìš©ì—ì„œ ë°œê²¬í•  ìˆ˜ ìˆëŠ” íŒ¨í„´ì´ë‚˜ ì˜ë¯¸
4. **ì œì•ˆì‚¬í•­**: ê°œì„ ì ì´ë‚˜ ë‹¤ìŒ ë‹¨ê³„ì— ëŒ€í•œ ì œì•ˆ

ìŒì„± ë‚´ìš©:
{transcription}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 200-300ì ë‚´ì™¸ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            
            messages: List[ChatCompletionMessageParam] = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìŒì„± íšŒê³  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìŒì„± ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            
            response = await self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=messages,
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            content = response.choices[0].message.content
            return content.strip() if content else ""
        
        except Exception as e:
            print(f"ìŒì„± íšŒê³  ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "âŒ ìŒì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def analyze_image_reflection(self, image_file_path: str) -> str:
        """ì´ë¯¸ì§€ íšŒê³  ë¶„ì„ (OpenAI Vision)"""
        if not self.is_available() or not self.client:
            return "âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            import base64
            
            # ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©
            async with aiofiles.open(image_file_path, "rb") as image_file:
                image_bytes = await image_file.read()
            base64_image = base64.b64encode(image_bytes).decode('utf-8')
            
            prompt = """
ì´ ì´ë¯¸ì§€ë¥¼ íšŒê³  ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì´ë¯¸ì§€ ë‚´ìš©**: ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ë³´ì´ëŠ”ì§€
2. **ê°ì •ì  ì˜ë¯¸**: ì´ ì´ë¯¸ì§€ê°€ ì „ë‹¬í•˜ëŠ” ê°ì •ì´ë‚˜ ë¶„ìœ„ê¸°
3. **íšŒê³ ì  ê´€ì **: ì´ ì´ë¯¸ì§€ê°€ ì‚¬ìš©ìì˜ í•˜ë£¨ë‚˜ ì‚¶ì—ì„œ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°€ì§€ëŠ”ì§€
4. **ì¸ì‚¬ì´íŠ¸**: ì´ë¯¸ì§€ë¥¼ í†µí•´ ë°œê²¬í•  ìˆ˜ ìˆëŠ” íŒ¨í„´ì´ë‚˜ ê¹¨ë‹¬ìŒ

íšŒê³ ì ì´ê³  ì„±ì°°ì ì¸ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
            
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            return response.choices[0].message.content.strip()
        
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "âŒ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def feedback(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """ìµœê·¼ íšŒê³ ì— ëŒ€í•œ AI í”¼ë“œë°± ì œê³µ"""
        user_id = update.effective_user.id
        # ìµœê·¼ íšŒê³  ê°€ì ¸ì˜¤ê¸°
        reflections = self.db.get_reflections(user_id)
        if not reflections:
            await update.message.reply_text("ìµœê·¼ íšŒê³ ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íšŒê³ ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.")
            return
        last_reflection = reflections[0]
        content = last_reflection['content']
        reflection_type = last_reflection.get('type', 'daily')
        # AI í”¼ë“œë°± ìƒì„±
        if self.ai_helper.is_available():
            feedback_text = await self.ai_helper.get_reflection_feedback(content, reflection_type)
        else:
            feedback_text = "AI í”¼ë“œë°± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        await update.message.reply_text(f"ğŸ“ ìµœê·¼ íšŒê³ :\n{content}\n\nğŸ’¡ AI í”¼ë“œë°±:\n{feedback_text}") 