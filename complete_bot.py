import logging
import datetime
import sqlite3
import pytz
import random
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, ContextTypes, filters, ConversationHandler
from database import Database
from ai_helper import AIHelper
from config import BOT_TOKEN, COMMANDS, DAILY_PROMPTS, WEEKLY_PROMPTS, MONTHLY_PROMPTS, AI_REFLECTION_PROMPTS, MOTIVATIONAL_QUOTES, COMPLETION_MESSAGES

# ëŒ€í™” ìƒíƒœ
WAITING_SCHEDULE_TITLE, WAITING_SCHEDULE_DESC, WAITING_SCHEDULE_DATE, WAITING_SCHEDULE_TIME = range(4)
WAITING_DAILY_FACT, WAITING_DAILY_THINK, WAITING_DAILY_TODO = range(4, 7)
WAITING_WEEKLY_FACT, WAITING_WEEKLY_THINK, WAITING_WEEKLY_TODO, WAITING_WEEKLY_TODO_FINAL = range(7, 10, 10, 11)
WAITING_MONTHLY_FACT, WAITING_MONTHLY_THINK, WAITING_MONTHLY_TODO, WAITING_MONTHLY_TODO_FINAL = range(10, 13, 13, 14)
WAITING_FEEDBACK = range(14, 15)
WAITING_EDIT_TITLE, WAITING_EDIT_DESC, WAITING_EDIT_DATE, WAITING_EDIT_TIME = range(15, 19)
WAITING_AI_REFLECTION = range(19, 20)
WAITING_CHATGPT = range(20, 21)
WAITING_ROUTINE_TITLE, WAITING_ROUTINE_DESC, WAITING_ROUTINE_FREQ, WAITING_ROUTINE_DAYS, WAITING_ROUTINE_DATE, WAITING_ROUTINE_TIME = range(21, 27)
WAITING_VOICE_REFLECTION, WAITING_IMAGE_REFLECTION = range(27, 29)

class ScheduleBot:
    def __init__(self):
        self.db = Database()
        self.ai_helper = AIHelper()
        self.user_states = {}  # ì‚¬ìš©ìë³„ ìƒíƒœ ì €ì¥
        self.ai_conversations = {}  # AI ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
    
    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """ë´‡ ì‹œì‘ ëª…ë ¹ì–´"""
        user = update.effective_user
        welcome_message = f"""
ğŸ‰ ì•ˆë…•í•˜ì„¸ìš” {user.first_name}ë‹˜! í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‘‹

ğŸ“… **ì¼ì •ê´€ë¦¬ & íšŒê³  ë´‡**ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!

âœ¨ **ì£¼ìš” ê¸°ëŠ¥:**
â€¢ ğŸ“ ì¼ì • ì¶”ê°€/ì¡°íšŒ/ìˆ˜ì •/ì‚­ì œ
â€¢ ğŸ”„ ë£¨í‹´(ë°˜ë³µ ì¼ì •) ê´€ë¦¬
â€¢ ğŸ“– ë‹¹ì¼/ì£¼ê°„/ì›”ê°„ íšŒê³  ì‘ì„±
â€¢ ğŸ¤ ìŒì„±/ì´ë¯¸ì§€ íšŒê³  (AI ë¶„ì„)
â€¢ ğŸ’¡ íšŒê³ ì— ëŒ€í•œ í”¼ë“œë°± ì œê³µ
â€¢ ğŸ¤– AIì™€ í•¨ê»˜í•˜ëŠ” ë¬µìƒ (GPT-4o-mini)
â€¢ ğŸ’¬ ChatGPTì™€ ììœ ë¡œìš´ ëŒ€í™”
â€¢ ğŸ”” ì•„ì¹¨ 8ì‹œ ìë™ ì•Œë¦¼
â€¢ ğŸ“¢ ì¼ì • ë³€ê²½ ì‹œ ì‹¤ì‹œê°„ ì•Œë¦¼
â€¢ ğŸ“Š í†µê³„ ë° ë™ê¸°ë¶€ì—¬

ğŸš€ **ì‹œì‘í•˜ê¸°:**
/help - ëª¨ë“  ëª…ë ¹ì–´ ë³´ê¸°
/add_schedule - ì²« ë²ˆì§¸ ì¼ì • ì¶”ê°€í•˜ê¸°
/daily_reflection - ì˜¤ëŠ˜ íšŒê³  ì‘ì„±í•˜ê¸°

ğŸ’¡ **íŒ:** ì¼ì •ì„ ì¶”ê°€/ìˆ˜ì •/ì‚­ì œí•˜ë©´ ìë™ìœ¼ë¡œ ì•Œë¦¼ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!

ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š
        """
        await update.message.reply_text(welcome_message)
    
    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """ë„ì›€ë§ ëª…ë ¹ì–´"""
        help_text = """
ğŸ“‹ **ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´**

ğŸ“… **ì¼ì • ê´€ë¦¬**
/add_schedule - ìƒˆë¡œìš´ ì¼ì • ì¶”ê°€
/view_schedule - ì¼ì • ëª©ë¡ ë³´ê¸°
/edit_schedule - ì¼ì • ìˆ˜ì •í•˜ê¸°
/delete_schedule - ì¼ì • ì‚­ì œí•˜ê¸°

ğŸ”„ **ë£¨í‹´ ê´€ë¦¬**
/add_routine - ìƒˆë¡œìš´ ë£¨í‹´ ì¶”ê°€
/view_routines - ë£¨í‹´ ëª©ë¡ ë³´ê¸°
/today_routines - ì˜¤ëŠ˜ì˜ ë£¨í‹´ ë³´ê¸°

ğŸ”” **ì•Œë¦¼ ê¸°ëŠ¥**
â€¢ ì¼ì • ì¶”ê°€/ìˆ˜ì •/ì‚­ì œ ì‹œ ìë™ ì•Œë¦¼
â€¢ ë§¤ì¼ ì•„ì¹¨ 8ì‹œ ì¼ì • ì•Œë¦¼
â€¢ ì¼ì • ì™„ë£Œ ì‹œ ì‘ì› ë©”ì‹œì§€

ğŸ“– **íšŒê³  ì‘ì„±**
/daily_reflection - ì˜¤ëŠ˜ í•˜ë£¨ íšŒê³  (Tí˜•)
/weekly_reflection - ì´ë²ˆ ì£¼ íšŒê³  (Tí˜•)
/monthly_reflection - ì´ë²ˆ ë‹¬ íšŒê³  (Tí˜•)
/voice_reflection - ìŒì„± íšŒê³  (AI ìŒì„± ë¶„ì„)
/image_reflection - ì´ë¯¸ì§€ íšŒê³  (AI ì´ë¯¸ì§€ ë¶„ì„)
/view_reflections - ì‘ì„±í•œ íšŒê³  ë³´ê¸°

ğŸ’¡ **í”¼ë“œë°± & ë¶„ì„**
/feedback - íšŒê³ ì— ëŒ€í•œ í”¼ë“œë°± ë°›ê¸°
/ai_feedback - AI í”¼ë“œë°± ë°›ê¸°
/ai_pattern_analysis - AI íšŒê³  íŒ¨í„´ ë¶„ì„
/ai_schedule_summary - AI ì¼ì • ìš”ì•½/ë¶„ì„

ğŸ¤– **AI ê¸°ëŠ¥**
/ai_reflection - AIì™€ í•¨ê»˜ ë¬µìƒí•˜ê¸°
/chatgpt - ChatGPTì™€ ììœ ë¡œìš´ ëŒ€í™”í•˜ê¸°

ğŸ“Š **í†µê³„ & ë™ê¸°ë¶€ì—¬**
/stats - ì£¼ê°„/ì›”ê°„ ì¼ì •/íšŒê³  í†µê³„
/motivate - ëª…ì–¸/ë™ê¸°ë¶€ì—¬ ëœë¤ ì „ì†¡

â“ **ê¸°íƒ€**
/help - ì´ ë„ì›€ë§ ë³´ê¸°
        """
        await update.message.reply_text(help_text)
    
    # ... (ê¸°ì¡´ í•¨ìˆ˜ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)
    
    # ìŒì„±/ì´ë¯¸ì§€ íšŒê³  ì§€ì› í•¨ìˆ˜ë“¤
    async def voice_reflection(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """ìŒì„± íšŒê³  ì‹œì‘"""
        user_id = update.effective_user.id
        today = datetime.datetime.now().strftime('%Y-%m-%d')
        existing_reflections = self.db.get_reflections(user_id, 'voice', today)
        if existing_reflections:
            await update.message.reply_text("ğŸ¤ ì˜¤ëŠ˜ ì´ë¯¸ ìŒì„± íšŒê³ ë¥¼ ì‘ì„±í•˜ì…¨ìŠµë‹ˆë‹¤. ìˆ˜ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
            return ConversationHandler.END
        
        context.user_data['voice_reflection'] = {}
        await update.message.reply_text("ğŸ¤ **ìŒì„± íšŒê³ **\n\nìŒì„± ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”. AIê°€ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  íšŒê³  ë‚´ìš©ì„ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤.")
        return WAITING_VOICE_REFLECTION
    
    async def handle_voice_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """ìŒì„± ë©”ì‹œì§€ ì²˜ë¦¬"""
        user_id = update.effective_user.id
        
        if not update.message.voice:
            await update.message.reply_text("âŒ ìŒì„± ë©”ì‹œì§€ê°€ ì•„ë‹™ë‹ˆë‹¤. ìŒì„± ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”.")
            return WAITING_VOICE_REFLECTION
        
        await update.message.reply_text("ğŸ¤ ìŒì„±ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        try:
            # ìŒì„± íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            voice_file = await context.bot.get_file(update.message.voice.file_id)
            voice_path = f"voice_{user_id}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.ogg"
            
            # ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (OpenAI Whisper ì‚¬ìš©)
            if self.ai_helper.is_available():
                transcription = self.ai_helper.transcribe_voice(voice_file.file_path)
                if transcription:
                    # AI ë¶„ì„ ë° íšŒê³  ìƒì„±
                    ai_analysis = self.ai_helper.analyze_voice_reflection(transcription)
                    
                    # íšŒê³  ì €ì¥
                    today = datetime.datetime.now().strftime('%Y-%m-%d')
                    content = f"[ìŒì„± ë³€í™˜] {transcription}\n\n[AI ë¶„ì„] {ai_analysis}"
                    success = self.db.add_reflection(user_id, 'voice', content, today)
                    
                    if success:
                        message = f"âœ… **ìŒì„± íšŒê³ ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!**\n\nğŸ¤ **ìŒì„± ë‚´ìš©**\n{transcription}\n\nğŸ¤– **AI ë¶„ì„**\n{ai_analysis}"
                        await update.message.reply_text(message)
                    else:
                        await update.message.reply_text("âŒ íšŒê³  ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                else:
                    await update.message.reply_text("âŒ ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                await update.message.reply_text("âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            
            context.user_data['voice_reflection'] = {}
            return ConversationHandler.END
            
        except Exception as e:
            print(f"ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            await update.message.reply_text("âŒ ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return WAITING_VOICE_REFLECTION
    
    async def image_reflection(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """ì´ë¯¸ì§€ íšŒê³  ì‹œì‘"""
        user_id = update.effective_user.id
        today = datetime.datetime.now().strftime('%Y-%m-%d')
        existing_reflections = self.db.get_reflections(user_id, 'image', today)
        if existing_reflections:
            await update.message.reply_text("ğŸ–¼ï¸ ì˜¤ëŠ˜ ì´ë¯¸ ì´ë¯¸ì§€ íšŒê³ ë¥¼ ì‘ì„±í•˜ì…¨ìŠµë‹ˆë‹¤. ìˆ˜ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
            return ConversationHandler.END
        
        context.user_data['image_reflection'] = {}
        await update.message.reply_text("ğŸ–¼ï¸ **ì´ë¯¸ì§€ íšŒê³ **\n\nì´ë¯¸ì§€ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”. AIê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  íšŒê³  ë‚´ìš©ì„ ìƒì„±í•´ë“œë¦½ë‹ˆë‹¤.")
        return WAITING_IMAGE_REFLECTION
    
    async def handle_image_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """ì´ë¯¸ì§€ ë©”ì‹œì§€ ì²˜ë¦¬"""
        user_id = update.effective_user.id
        
        if not update.message.photo:
            await update.message.reply_text("âŒ ì´ë¯¸ì§€ê°€ ì•„ë‹™ë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”.")
            return WAITING_IMAGE_REFLECTION
        
        await update.message.reply_text("ğŸ–¼ï¸ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        try:
            # ì´ë¯¸ì§€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            photo = update.message.photo[-1]  # ê°€ì¥ í° í•´ìƒë„ ì„ íƒ
            image_file = await context.bot.get_file(photo.file_id)
            
            # ì´ë¯¸ì§€ ë¶„ì„ (OpenAI Vision ì‚¬ìš©)
            if self.ai_helper.is_available():
                analysis = self.ai_helper.analyze_image_reflection(image_file.file_path)
                if analysis:
                    # íšŒê³  ì €ì¥
                    today = datetime.datetime.now().strftime('%Y-%m-%d')
                    content = f"[ì´ë¯¸ì§€ ë¶„ì„] {analysis}"
                    success = self.db.add_reflection(user_id, 'image', content, today)
                    
                    if success:
                        message = f"âœ… **ì´ë¯¸ì§€ íšŒê³ ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!**\n\nğŸ–¼ï¸ **AI ë¶„ì„**\n{analysis}"
                        await update.message.reply_text(message)
                    else:
                        await update.message.reply_text("âŒ íšŒê³  ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                else:
                    await update.message.reply_text("âŒ ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                await update.message.reply_text("âŒ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            
            context.user_data['image_reflection'] = {}
            return ConversationHandler.END
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            await update.message.reply_text("âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return WAITING_IMAGE_REFLECTION

    async def motivate(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        ëœë¤ ëª…ì–¸/ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ì „ì†¡
        """
        quote = random.choice(MOTIVATIONAL_QUOTES)
        await update.message.reply_text(f"ğŸ’¡ {quote}")
        if self.ai_helper.is_available():
            ai_msg = await self.ai_helper.get_motivational_message()
            await update.message.reply_text(f"ğŸ¤– AI ë™ê¸°ë¶€ì—¬: {ai_msg}")

    async def ai_reflection(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        AIì™€ í•¨ê»˜ ë¬µìƒ/ê³ ë¯¼/ìê¸°ì„±ì°° ëŒ€í™” (GPT-4o-mini)
        """
        await update.message.reply_text(
            "ğŸ§˜ <b>AIì™€ í•¨ê»˜ ë¬µìƒì„ ì‹œì‘í•©ë‹ˆë‹¤!</b>\n\nììœ ë¡­ê²Œ ì˜¤ëŠ˜ì˜ ê°ì •, ê³ ë¯¼, ìƒê°, ëª©í‘œ ë“±ì„ ì ì–´ì£¼ì„¸ìš”.\nAIê°€ ë”°ëœ»í•˜ê²Œ ì½”ì¹­í•´ë“œë¦½ë‹ˆë‹¤.",
            parse_mode='HTML'
        )
        return WAITING_AI_REFLECTION

    async def ai_reflection_input(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_input = update.message.text
        if self.ai_helper.is_available():
            response = await self.ai_helper.get_ai_reflection_guidance(user_input)
        else:
            response = "AI ë¬µìƒ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        await update.message.reply_text(response, parse_mode='HTML')
        return ConversationHandler.END

    async def chatgpt(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        ChatGPTì™€ ììœ  ëŒ€í™” (ì§ˆë¬¸/ìƒë‹´/ì¡ë‹´ ë“±)
        """
        await update.message.reply_text(
            "ğŸ’¬ <b>ChatGPTì™€ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!</b>\n\nê¶ê¸ˆí•œ ì , ê³ ë¯¼, ì¡ë‹´ ë“± ë¬´ì—‡ì´ë“  ì…ë ¥í•´ë³´ì„¸ìš”.",
            parse_mode='HTML'
        )
        return WAITING_CHATGPT

    async def chatgpt_input(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_message = update.message.text
        user_id = update.effective_user.id
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ (ì˜µì…˜)
        if user_id not in self.ai_conversations:
            self.ai_conversations[user_id] = []
        self.ai_conversations[user_id].append({"role": "user", "content": user_message})
        if self.ai_helper.is_available():
            response = await self.ai_helper.chat_with_gpt(user_message, self.ai_conversations[user_id])
        else:
            response = "AI ëŒ€í™” ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        self.ai_conversations[user_id].append({"role": "assistant", "content": response})
        await update.message.reply_text(response, parse_mode='HTML')
        return ConversationHandler.END

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if not BOT_TOKEN:
        print("âŒ BOT_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    bot = ScheduleBot()
    
    # Application ìƒì„±
    application = Application.builder().token(BOT_TOKEN).build()
    
    # í•¸ë“¤ëŸ¬ ë“±ë¡
    application.add_handler(CommandHandler("start", bot.start))
    application.add_handler(CommandHandler("help", bot.help_command))
    application.add_handler(CommandHandler("voice_reflection", bot.voice_reflection))
    application.add_handler(CommandHandler("image_reflection", bot.image_reflection))
    application.add_handler(CommandHandler("motivate", bot.motivate))
    
    # ìŒì„± íšŒê³  í•¸ë“¤ëŸ¬
    voice_reflection_handler = ConversationHandler(
        entry_points=[CommandHandler('voice_reflection', bot.voice_reflection)],
        states={
            WAITING_VOICE_REFLECTION: [MessageHandler(filters.VOICE, bot.handle_voice_message)],
        },
        fallbacks=[CommandHandler('cancel', bot.cancel)]
    )
    
    # ì´ë¯¸ì§€ íšŒê³  í•¸ë“¤ëŸ¬
    image_reflection_handler = ConversationHandler(
        entry_points=[CommandHandler('image_reflection', bot.image_reflection)],
        states={
            WAITING_IMAGE_REFLECTION: [MessageHandler(filters.PHOTO, bot.handle_image_message)],
        },
        fallbacks=[CommandHandler('cancel', bot.cancel)]
    )
    
    application.add_handler(voice_reflection_handler)
    application.add_handler(image_reflection_handler)
    
    # ë´‡ ì‹œì‘
    print("ğŸ¤– í…”ë ˆê·¸ë¨ ë´‡ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤...")
    if bot.ai_helper.is_available():
        print("âœ… AI ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âš ï¸  AI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    application.run_polling()

if __name__ == '__main__':
    main() 